{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install following packages\n",
    "* python-dotenv\n",
    "* openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\python312\\lib\\site-packages (1.0.0)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World! by Yasir\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello, World! by Yasir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an OpenAI Client\n",
    "* Step 3.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "_ : bool = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "client : OpenAI = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello World Code\n",
    "* Step 3.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sum of 1 + 1 is 2.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "\n",
    "def chat_completion(prompt : str)-> str:\n",
    "    response : ChatCompletion =client.chat.completions.create(\n",
    "        messages =[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model = 'gpt-3.5-turbo-1106',\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "chat_completion(\"What is sum of 1 + 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muliple Roles\n",
    "* Step 3.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Below is a simple example of a \"Hello World\" code using Next.js with TypeScript:\n",
      "\n",
      "```tsx\n",
      "// pages/index.tsx\n",
      "\n",
      "const Home: React.FC = () => {\n",
      "  return (\n",
      "    <div>\n",
      "      <h1>Hello, World!</h1>\n",
      "    </div>\n",
      "  );\n",
      "};\n",
      "\n",
      "export default Home;\n",
      "```\n",
      "\n",
      "In this example, we have a functional component called Home that simply renders a \"Hello, World!\" heading. This component is the main page of the application and is located in the `index.tsx` file within the `pages` directory, which is a special directory in Next.js for creating pages.\n"
     ]
    }
   ],
   "source": [
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "\n",
    "def chat_completion(prompt : str)-> str:\n",
    "    response : ChatCompletion =client.chat.completions.create(\n",
    "        messages =[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an accomplished expert specializing in Next.js, React.js, typescript and Tailwind CSS, with a background as a personal tutor in web development. Your task is to respond to user queries related to coding CRUD APIs. Users may seek your guidance on implementing CRUD functionalities using a hypothetical example. Additionally, users may present code snippets for error-checking, share entire components for review, or provide error messages from server or client consoles, seeking your expertise in identifying and rectifying issues. Your responses should include comprehensive code snippets with clear explanations, offering guidance on potential errors and suggesting corrective measures. Support your explanations with code snippets to enhance clarity and provide users with actionable insights.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model = 'gpt-3.5-turbo-1106',\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(chat_completion(\"Give a basic hello world code\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Response\n",
    "* Step 3.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This\n",
      " is\n",
      " a\n",
      " test\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=[{\"role\": \"user\",\"content\": \"Say this is a test\"}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for part in stream:\n",
    "    print(part.choices[0].delta.content or \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To\n",
      " calculate\n",
      " the\n",
      " final\n",
      " velocity\n",
      " of\n",
      " the\n",
      " rocket\n",
      " if\n",
      " the\n",
      " fuel\n",
      " is\n",
      " increased\n",
      " to\n",
      " \n",
      "10\n",
      "%,\n",
      " we\n",
      " need\n",
      " to\n",
      " use\n",
      " the\n",
      " rocket\n",
      " equation\n",
      ":\n",
      "\n",
      "\n",
      "Δ\n",
      "v\n",
      " =\n",
      " Ve\n",
      " *\n",
      " ln\n",
      "(m\n",
      "0\n",
      "/m\n",
      "f\n",
      ")\n",
      "\n",
      "\n",
      "Where\n",
      ":\n",
      "\n",
      "Δ\n",
      "v\n",
      " =\n",
      " final\n",
      " velocity\n",
      "\n",
      "\n",
      "Ve\n",
      " =\n",
      " effective\n",
      " exhaust\n",
      " velocity\n",
      "\n",
      "\n",
      "m\n",
      "0\n",
      " =\n",
      " initial\n",
      " mass\n",
      " of\n",
      " the\n",
      " rocket\n",
      " (\n",
      "including\n",
      " fuel\n",
      ")\n",
      "\n",
      "mf\n",
      " =\n",
      " final\n",
      " mass\n",
      " of\n",
      " the\n",
      " rocket\n",
      " (\n",
      "after\n",
      " exp\n",
      "elling\n",
      " the\n",
      " fuel\n",
      ")\n",
      "\n",
      "\n",
      "If\n",
      " the\n",
      " ratio\n",
      " of\n",
      " fuel\n",
      " is\n",
      " changed\n",
      " to\n",
      " \n",
      "10\n",
      "%,\n",
      " then\n",
      " the\n",
      " final\n",
      " mass\n",
      " of\n",
      " the\n",
      " rocket\n",
      " (\n",
      "mf\n",
      ")\n",
      " will\n",
      " be\n",
      " \n",
      "90\n",
      "%\n",
      " of\n",
      " the\n",
      " initial\n",
      " mass\n",
      " (\n",
      "m\n",
      "0\n",
      "),\n",
      " as\n",
      " \n",
      "10\n",
      "%\n",
      " of\n",
      " the\n",
      " initial\n",
      " mass\n",
      " will\n",
      " be\n",
      " fuel\n",
      ".\n",
      "\n",
      "\n",
      "Ass\n",
      "uming\n",
      " the\n",
      " effective\n",
      " exhaust\n",
      " velocity\n",
      " (\n",
      "Ve\n",
      ")\n",
      " remains\n",
      " constant\n",
      ",\n",
      " you\n",
      " would\n",
      " use\n",
      " the\n",
      " new\n",
      " ratio\n",
      " of\n",
      " masses\n",
      " to\n",
      " calculate\n",
      " the\n",
      " final\n",
      " velocity\n",
      " of\n",
      " the\n",
      " rocket\n",
      " with\n",
      " \n",
      "10\n",
      "%\n",
      " fuel\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def chat_completion(prompt: str) -> str:\n",
    "    stream = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=[{\"role\": \"user\",\"content\": prompt}],\n",
    "    stream=True,\n",
    "    )\n",
    "    for part in stream:\n",
    "        print(part.choices[0].delta.content or \"\")\n",
    "\n",
    "chat_completion(\"What would be the final velocity of the rocket if fuel would be raised to 10%?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON Mode \n",
    "* Step 3.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"months\": [\n",
      "    \"January\",\n",
      "    \"March\",\n",
      "    \"May\",\n",
      "    \"July\",\n",
      "    \"August\",\n",
      "    \"October\",\n",
      "    \"December\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  response_format={ \"type\": \"json_object\" },\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
    "    {\"role\": \"user\", \"content\": \"List of months that have 31 days\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month at 0 Insex: - January\n",
      "\n",
      "All Months in JSON Format: - \n",
      "['January', 'March', 'May', 'July', 'August', 'October', 'December']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# parse response:\n",
    "obj: dict[str, list[str]] = json.loads(response.choices[0].message.content)\n",
    "\n",
    "# the result is a Python dictionary:\n",
    "for month in obj:\n",
    "    print(\"Month at 0 Insex: - \"+ obj[month][0])\n",
    "    print(\"\\nAll Months in JSON Format: - \")\n",
    "    print( obj[month])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling\n",
    "* Step 3.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location:str, unit:str=\"fahrenheit\")->str:\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.chat.chat_completion import ChatCompletionMessage, ChatCompletion\n",
    "# from openai.types.chat.chat_completion import ChatCompletionMessageParam, ChatCompletionMessageParam\n",
    "\n",
    "def run_conversation(main_request: str)->str:\n",
    "    # Step 1: send the conversation and available functions to the model\n",
    "    messages = [{\"role\": \"user\", \"content\": main_request}]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # First Request\n",
    "    response: ChatCompletion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message: ChatCompletionMessage = response.choices[0].message\n",
    "    display(\"* First Response: \", dict(response_message))\n",
    "\n",
    "    tool_calls = response_message.tool_calls\n",
    "    display(\"* First Reponse Tool Calls: \", list(tool_calls))\n",
    "\n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    if tool_calls:\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        \n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        \n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                location=function_args.get(\"location\"),\n",
    "                unit=function_args.get(\"unit\"),\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )  # extend conversation with function response\n",
    "        display(\"* Second Request Messages: \", list(messages))\n",
    "        second_response: ChatCompletion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        print(\"* Second Response: \", dict(second_response))\n",
    "        return second_response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'* First Response: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'content': None,\n",
       " 'role': 'assistant',\n",
       " 'function_call': None,\n",
       " 'tool_calls': [ChatCompletionMessageToolCall(id='call_VtnPtDfksgLbsINHBTZIBDIA', function=Function(arguments='{\"location\": \"San Francisco\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'),\n",
       "  ChatCompletionMessageToolCall(id='call_Xw5pTp6cb7RjlIqhhFcqKYdj', function=Function(arguments='{\"location\": \"Tokyo\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'),\n",
       "  ChatCompletionMessageToolCall(id='call_ofmd3JhoOlFGFvZnsv2pp91c', function=Function(arguments='{\"location\": \"Paris\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'* First Reponse Tool Calls: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[ChatCompletionMessageToolCall(id='call_VtnPtDfksgLbsINHBTZIBDIA', function=Function(arguments='{\"location\": \"San Francisco\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'),\n",
       " ChatCompletionMessageToolCall(id='call_Xw5pTp6cb7RjlIqhhFcqKYdj', function=Function(arguments='{\"location\": \"Tokyo\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'),\n",
       " ChatCompletionMessageToolCall(id='call_ofmd3JhoOlFGFvZnsv2pp91c', function=Function(arguments='{\"location\": \"Paris\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun_conversation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms the weather like in San Francisco, Tokyo, and Paris?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mrun_conversation\u001b[1;34m(main_request)\u001b[0m\n\u001b[0;32m     53\u001b[0m function_name \u001b[38;5;241m=\u001b[39m tool_call\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m     54\u001b[0m function_to_call \u001b[38;5;241m=\u001b[39m available_functions[function_name]\n\u001b[1;32m---> 55\u001b[0m function_args \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mloads(tool_call\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39marguments)\n\u001b[0;32m     56\u001b[0m function_response \u001b[38;5;241m=\u001b[39m function_to_call(\n\u001b[0;32m     57\u001b[0m     location\u001b[38;5;241m=\u001b[39mfunction_args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     58\u001b[0m     unit\u001b[38;5;241m=\u001b[39mfunction_args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munit\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     59\u001b[0m )\n\u001b[0;32m     60\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     61\u001b[0m     {\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_call_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_call\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     }\n\u001b[0;32m     67\u001b[0m )  \u001b[38;5;66;03m# extend conversation with function response\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "run_conversation(\"What's the weather like in San Francisco, Tokyo, and Paris?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything is API\n",
    "* Step 8.01 - Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'requests' from 'e:\\\\Users\\\\Huzaifa Enterprise\\\\anaconda3\\\\envs\\\\python12\\\\Lib\\\\site-packages\\\\requests\\\\__init__.py'>\n",
      "e:\\Users\\Huzaifa Enterprise\\anaconda3\\envs\\python12\\Lib\\site-packages\\requests\\__init__.py\n",
      "2.31.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "print(requests)\n",
    "print(requests.__file__)\n",
    "print(requests.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Response'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status_code 200\n",
      "response.text {\"status\":\"OK\"} <class 'str'>\n",
      "response.headers {'Date': 'Mon, 15 Jan 2024 16:22:11 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '15', 'Connection': 'keep-alive', 'x-powered-by': 'Express', 'etag': 'W/\"f-v/Y1JusChTxrQUzPtNAKycooOTA\"'}\n"
     ]
    }
   ],
   "source": [
    "from requests.models import Response\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "\n",
    "response: Response = requests.get('https://simple-books-api.glitch.me/status')\n",
    "# response: Response = requests.get('https://requests.readthedocs.io/en/latest')\n",
    "display(\"Response\",response)\n",
    "\n",
    "\n",
    "status_code : int = response.status_code\n",
    "print(\"Status_code\",status_code)\n",
    "\n",
    "# json_obj : dict = response.json()\n",
    "# print(\"Json_obj\",json_obj, type(json_obj))\n",
    "\n",
    "txt: str = response.text\n",
    "print(\"response.text\",txt,type(txt))\n",
    "\n",
    "headers: CaseInsensitiveDict = response.headers\n",
    "print(\"response.headers\",headers)\n",
    "#\n",
    "# print(response.status_code, response.json(), response.text, response.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status_code :  200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 1, 'name': 'The Russian', 'type': 'fiction', 'available': True},\n",
       " {'id': 2, 'name': 'Just as I Am', 'type': 'non-fiction', 'available': False},\n",
       " {'id': 3, 'name': 'The Vanishing Half', 'type': 'fiction', 'available': True},\n",
       " {'id': 4,\n",
       "  'name': 'The Midnight Library',\n",
       "  'type': 'fiction',\n",
       "  'available': True},\n",
       " {'id': 5, 'name': 'Untamed', 'type': 'non-fiction', 'available': True},\n",
       " {'id': 6,\n",
       "  'name': 'Viscount Who Loved Me',\n",
       "  'type': 'fiction',\n",
       "  'available': True}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'response.headers'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Date': 'Mon, 15 Jan 2024 16:24:51 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '417', 'Connection': 'keep-alive', 'x-powered-by': 'Express', 'etag': 'W/\"1a1-MfqhfTYtZO2sguD1mJq8Vf41WjU\"'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "response: Response = requests.get('https://simple-books-api.glitch.me/books')\n",
    "\n",
    "\n",
    "status_code : int = response.status_code\n",
    "print(\"Status_code : \",status_code)\n",
    "\n",
    "json_obj : list = response.json()\n",
    "display(json_obj)\n",
    "\n",
    "\n",
    "headers: CaseInsensitiveDict = response.headers\n",
    "display(\"response.headers\",headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status_code :  200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 5,\n",
       " 'name': 'Untamed',\n",
       " 'author': 'Glennon Doyle',\n",
       " 'type': 'non-fiction',\n",
       " 'price': 15.5,\n",
       " 'current-stock': 20,\n",
       " 'available': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'response.headers'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Date': 'Mon, 15 Jan 2024 16:27:34 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '120', 'Connection': 'keep-alive', 'x-powered-by': 'Express', 'etag': 'W/\"78-j/iSKeyVOvbJ1tvDEXM1nGhdATo\"'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "response: Response = requests.get('https://simple-books-api.glitch.me/books/5')\n",
    "\n",
    "\n",
    "status_code : int = response.status_code\n",
    "print(\"Status_code : \",status_code)\n",
    "\n",
    "json_obj : list = response.json()\n",
    "display(json_obj)\n",
    "\n",
    "\n",
    "headers: CaseInsensitiveDict = response.headers\n",
    "display(\"response.headers\",headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requests \n",
    "* Post Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status_code :  201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accessToken': 'f24c03e0c808eec60ba4fbcbb8700a7347aba56a31b1fa728b81d096a14e5d74'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "credentials = {\n",
    "   \"clientName\": \"Yasir\",\n",
    "   \"clientEmail\": \"imyasir79@hotmail.com\"\n",
    "}\n",
    "\n",
    "response1: Response = requests.post('https://simple-books-api.glitch.me/api-clients/', json = credentials)\n",
    "\n",
    "\n",
    "status_code : int = response1.status_code\n",
    "print(\"Status_code : \",status_code)\n",
    "\n",
    "json_obj : list = response1.json()\n",
    "display(json_obj)\n",
    "\n",
    "\n",
    "# headers: CaseInsensitiveDict = response.headers\n",
    "# display(\"response.headers\",headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"created\":true,\"orderId\":\"JPVz-hfLhIBauc10caADb\"}'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headers: dict = {'Authorization': 'Bearer f24c03e0c808eec60ba4fbcbb8700a7347aba56a31b1fa728b81d096a14e5d74'}\n",
    "\n",
    "order: dict = {\n",
    "    'bookId': 1,\n",
    "    'customerName': \"Nasir\"\n",
    "}\n",
    "\n",
    "response2: Response = requests.post('https://simple-books-api.glitch.me/orders/', json = order, headers = headers)\n",
    "\n",
    "status_code: int = response2.status_code\n",
    "print(status_code)\n",
    "\n",
    "bookOrdered: dict = response2.text\n",
    "display(bookOrdered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[{\"id\":\"7o-IDd2VQHebNeNUG_Vax\",\"bookId\":1,\"customerName\":\"Nasir\",\"createdBy\":\"ff9687483b73caf6d532e22498e215575aaddae8fb35dec39c3f35f33323647e\",\"quantity\":1,\"timestamp\":1705338044669},{\"id\":\"GYYf52CWnoiDdx_G0wCeM\",\"bookId\":1,\"customerName\":\"Nasir\",\"createdBy\":\"ff9687483b73caf6d532e22498e215575aaddae8fb35dec39c3f35f33323647e\",\"quantity\":1,\"timestamp\":1705338064976},{\"id\":\"JPVz-hfLhIBauc10caADb\",\"bookId\":1,\"customerName\":\"Nasir\",\"createdBy\":\"ff9687483b73caf6d532e22498e215575aaddae8fb35dec39c3f35f33323647e\",\"quantity\":1,\"timestamp\":1705338096652}]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headers: dict = {'Authorization': 'Bearer f24c03e0c808eec60ba4fbcbb8700a7347aba56a31b1fa728b81d096a14e5d74'}\n",
    "\n",
    "order: dict = {\n",
    "    'bookId': 1,\n",
    "    'customerName': \"Nasir\"\n",
    "}\n",
    "\n",
    "response2: Response = requests.get('https://simple-books-api.glitch.me/orders/',  headers = headers) #, json = order,\n",
    "\n",
    "status_code: int = response2.status_code\n",
    "print(status_code)\n",
    "\n",
    "bookOrdered: dict = response2.text\n",
    "display(bookOrdered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pydantic\n",
    "* (practice to be done Later)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
